{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFFShKxXKV/GUoCci+PmGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naveenand/Langchain/blob/main/buiding_research_assistent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hat4YOtwuclt"
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4 openai langchain langsmith duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
        "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
        "import json"
      ],
      "metadata": {
        "id": "SJrGlzfpXou1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "id": "_BfueAnRI_3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from uuid import uuid4\n",
        "\n",
        "unique_id = uuid4().hex[0:8]\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
      ],
      "metadata": {
        "id": "M0hqqirQKTac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"your_langsmith_api\""
      ],
      "metadata": {
        "id": "sfxCzohBLWBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://blog.langchain.dev/pinecone-serverless/'"
      ],
      "metadata": {
        "id": "p5XWNtifl9Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESULTS_PER_QUESTION = 2\n",
        "\n",
        "ddg_search = DuckDuckGoSearchAPIWrapper()\n"
      ],
      "metadata": {
        "id": "rXiBH2bLW3QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def web_search(query: str, num_results: int = RESULTS_PER_QUESTION):\n",
        "    results = ddg_search.results(query, num_results)\n",
        "    return [r[\"link\"] for r in results]"
      ],
      "metadata": {
        "id": "mrgyx7cYY2Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_text(url: str):\n",
        "    # Send a GET request to the webpage\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if response.status_code == 200:\n",
        "            # Parse the content of the request with BeautifulSoup\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            # Extract all text from the webpage\n",
        "            page_text = soup.get_text(separator=\" \", strip=True)\n",
        "\n",
        "            # Print the extracted text\n",
        "            return page_text\n",
        "        else:\n",
        "            return f\"Failed to retrieve the webpage: Status code {response.status_code}\"\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return f\"Failed to retrieve the webpage: {e}\""
      ],
      "metadata": {
        "id": "rXJ09CcN5D71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUMMARY_TEMPLATE = \"\"\"{text}\n",
        "-----------\n",
        "Using the above text, answer in short the following question:\n",
        "> {question}\n",
        "-----------\n",
        "if the question cannot be answered using the text, imply summarize the text. Include all factual information, numbers, stats etc if available.\"\"\"\n"
      ],
      "metadata": {
        "id": "OBF52L0W5FCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUMMARY_PROMPT = ChatPromptTemplate.from_template(SUMMARY_TEMPLATE)"
      ],
      "metadata": {
        "id": "BicQ8a1I7vF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_content = scrape_text(url)[:10000]"
      ],
      "metadata": {
        "id": "LEqpGVTQHbE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_and_summarize_chain = RunnablePassthrough.assign(\n",
        "    summary = RunnablePassthrough.assign(\n",
        "    text=lambda x: scrape_text(x[\"url\"])[:10000]\n",
        ") | SUMMARY_PROMPT | ChatOpenAI(model=\"gpt-3.5-turbo-1106\") | StrOutputParser()\n",
        ") | (lambda x: f\"URL: {x['url']}\\n\\nSUMMARY: {x['summary']}\")"
      ],
      "metadata": {
        "id": "NIin9qWXHjd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_search_chain = RunnablePassthrough.assign(\n",
        "    urls = lambda x: web_search(x['question'])\n",
        ") | (lambda x: [{'question': x['question'],'url': u} for u in x['urls']]) | scrape_and_summarize_chain.map()"
      ],
      "metadata": {
        "id": "joU3Zk-XZQJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEARCH_PROMPT = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"user\",\n",
        "            \"Write 1 google search queries to search online that form an \"\n",
        "            \"objective opinion from the following: {question}\\n\"\n",
        "            \"You must respond with a list of strings in the following format: \"\n",
        "            '[\"query 1\"].',\n",
        "        ),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "JmVfeKZRJ3sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_question_chain = SEARCH_PROMPT | ChatOpenAI(model ='gpt-3.5-turbo-1106',temperature=0.1) | StrOutputParser() | json.loads"
      ],
      "metadata": {
        "id": "oxdT8YERcuvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_research_chain  = search_question_chain | (lambda x: [{'question':q} for q in x]) | web_search_chain.map()"
      ],
      "metadata": {
        "id": "IEwfyYNldvaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WRITER_SYSTEM_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\""
      ],
      "metadata": {
        "id": "lAuqmUfBp3Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESEARCH_REPORT_TEMPLATE = \"\"\"Information:\n",
        "--------\n",
        "{research_summary}\n",
        "--------\n",
        "Using the above information, answer the following question or topic: \"{question}\" in a detailed report -- \\\n",
        "The report should focus on the answer to the question, should be well structured, informative, \\\n",
        "in depth, with facts and numbers if available and a minimum of 1,200 words.\n",
        "You should strive to write the report as long as you can using all relevant and necessary information provided.\n",
        "You must write the report with markdown syntax.\n",
        "You MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\n",
        "Write all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\n",
        "You must write the report in apa format.\n",
        "Please do your best, this is very important to my career.\"\"\""
      ],
      "metadata": {
        "id": "1CPYxbNBp22S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", WRITER_SYSTEM_PROMPT),\n",
        "        (\"user\", RESEARCH_REPORT_TEMPLATE),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "umkbT_dxp2yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collapse_list_of_lists(list_of_lists):\n",
        "    content = []\n",
        "    for l in list_of_lists:\n",
        "        content.append(\"\\n\\n\".join(l))\n",
        "    return \"\\n\\n\".join(content)"
      ],
      "metadata": {
        "id": "YIbe8Fcjp2sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RunnablePassthrough.assign(\n",
        "    research_summary= full_research_chain | collapse_list_of_lists\n",
        ") | prompt | ChatOpenAI(model=\"gpt-3.5-turbo-1106\") | StrOutputParser()"
      ],
      "metadata": {
        "id": "woy_FyDRp2pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\n",
        "    {\n",
        "        'question': \"how is the difference between langsmith and langchain\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "ylMwU9WWIn2C",
        "outputId": "7b394a2a-0d51-478c-a9c2-f55f7cdabd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# LangSmith vs LangChain: Understanding the Difference\\n\\nLangSmith and LangChain are two integral components in the realm of LLM (Language, Logic, and Meaning) applications. Both developed by the same company, these platforms serve distinct purposes while also complementing each other to enhance the development and deployment of LLM applications. In this comprehensive report, we will delve into the differences between LangSmith and LangChain, exploring their individual functionalities, features, and how they work in tandem to provide a comprehensive ecosystem for LLM application development.\\n\\n## LangSmith: A Platform for Debugging, Testing, and Monitoring LLM Applications\\n\\nLangSmith, as described, is a platform specifically designed for debugging, testing, evaluating, and monitoring LLM applications. It serves as a comprehensive toolkit for developers and engineers working with LLM frameworks, providing essential features to streamline the development process. Some of the key functionalities offered by LangSmith include:\\n\\n1. **Debugging and Testing**: LangSmith offers robust debugging and testing capabilities, allowing developers to identify and resolve issues within LLM applications efficiently.\\n\\n2. **API and Environment Setup**: The platform facilitates the seamless setup of APIs and environments, simplifying the configuration process for LLM applications.\\n\\n3. **Tracing Capabilities**: LangSmith incorporates advanced tracing capabilities, enabling developers to track the execution and performance of LLM applications effectively.\\n\\n4. **Cookbook with Real-World Examples**: The inclusion of a Cookbook filled with real-world examples provides developers with valuable reference materials and best practices for LLM application development.\\n\\n## LangChain: An Open-Source Framework for Building Intelligent Agents and Chains\\n\\nOn the other hand, LangChain serves as an open-source framework specifically tailored for building intelligent agents and chains based on any LLM framework. It offers a diverse set of features geared towards the development of intelligent and adaptive systems. Some of the primary features of LangChain include:\\n\\n1. **Framework Flexibility**: LangChain is designed to be adaptable to any LLM framework, providing developers with the flexibility to leverage their preferred frameworks for building intelligent agents and chains.\\n\\n2. **Enhanced Monitoring and Evaluation**: The framework incorporates mechanisms for monitoring and evaluating the performance of intelligent agents and chains, crucial for ensuring optimal functionality.\\n\\n3. **Interoperability with LangSmith**: LangChain seamlessly integrates with LangSmith, leveraging the debugging, testing, and monitoring capabilities offered by LangSmith to enhance the development and deployment of intelligent agents and chains.\\n\\n## Differentiating Factors\\n\\n### Target Audience\\n\\nOne of the fundamental differences between LangSmith and LangChain lies in their target audience. LangSmith primarily caters to developers and engineers involved in the development and maintenance of LLM applications. Its focus on debugging, testing, and monitoring aligns with the requirements of individuals directly engaged in the technical aspects of LLM application development.\\n\\nOn the other hand, LangChain targets developers and researchers working on intelligent agents and chains within the LLM domain. Its emphasis on building adaptive systems and leveraging LLM frameworks reflects its appeal to a more specialized audience.\\n\\n### Functionality and Integration\\n\\nWhile LangSmith is geared towards providing essential tools for LLM application development, LangChain focuses on empowering developers to build intelligent agents and chains. However, an important point of intersection is the seamless integration between the two platforms. LangChain leverages the debugging, testing, and monitoring capabilities of LangSmith, underscoring their collaborative nature in enhancing the development and deployment of LLM applications and intelligent systems.\\n\\n### Open-Source Framework\\n\\nLangChain's status as an open-source framework sets it apart from LangSmith. The open-source nature of LangChain encourages collaboration, innovation, and community-driven development, fostering a vibrant ecosystem for intelligent agent and chain development within the LLM domain.\\n\\n## Conclusion\\n\\nIn conclusion, the difference between LangSmith and LangChain is grounded in their distinct functionalities and target audiences within the LLM landscape. While LangSmith serves as a comprehensive platform for debugging, testing, and monitoring LLM applications, LangChain is an open-source framework tailored for building intelligent agents and chains. Despite their unique roles, both platforms work in synergy to enhance the development and deployment of LLM applications, exemplifying a cohesive ecosystem that caters to diverse aspects of LLM technology.\\n\\nReferences:\\n- LangSmith and LangChain. (n.d.). Retrieved from https://cheatsheet.md/langchain-tutorials/langsmith.en\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ]
}